# Database

# Optimizing queries performance

a. What is query execution plan? How can you generate it?

Optimizing database query performance involves several key strategies:

**Effective Indexing**: Create indexes on frequently queried columns, especially those used in WHERE clauses, JOIN
conditions, and ORDER BY clauses. This allows the database to quickly locate relevant data without scanning entire
tables.

**Avoid SELECT**: Specify only the columns required, reducing the amount of data retrieved and transferred, improving
network performance and memory usage.

**Optimize JOIN Operations**: Choose the most appropriate JOIN type (e.g., INNER JOIN, LEFT JOIN) and ensure JOIN
conditions are indexed.

**Filter Early**: Use WHERE clauses to filter data as early as possible in the query processing, reducing the dataset
size for subsequent operations.

**Use Appropriate Data Types**: Select the most suitable and smallest possible data types for columns, minimizing
storage space and improving query efficiency.

**Update Statistics**: Ensure database statistics are up-to-date, as the query optimizer relies on them to create
efficient execution plans.

**Avoid Subqueries where possible**: In some cases, Common Table Expressions (CTEs) or JOIN operations can be more
efficient than deeply nested subqueries.

**Minimize Wildcard Usage**: Avoid leading wildcards (%) in LIKE clauses, as they can prevent index usage.

**What is a Query Execution Plan?**

A query execution plan is a detailed blueprint generated by the database management system (DBMS) that outlines the
sequence of operations the database will perform to execute a given SQL query. It illustrates how the database will
access, filter, join, and sort data to produce the query results. This plan provides insights into the database's chosen
strategy, including index usage, table scans, join algorithms, and the estimated cost of each operation.

**How to Generate a Query Execution Plan**

The method for generating a query execution plan varies slightly depending on the specific database system: SQL Server.

```sql

    EXPLAIN ANALYZE SELECT * FROM Employees WHERE EmployeeID = 1;
```

In SQL Server Management Studio (SSMS), you can also right-click in the query window and select "Display Estimated
Execution Plan" or use the corresponding toolbar button. To get the actual plan after execution, you can use "Include
Actual Execution Plan."

PostgreSQL.

```sql

    EXPLAIN ANALYZE SELECT * FROM Customers WHERE City = 'New York';
```

The ANALYZE keyword executes the query and provides actual runtime statistics in addition to the plan. MySQL.

```sql

    EXPLAIN SELECT ProductName, Price FROM Products WHERE CategoryID = 5;
```

This command will provide information about how MySQL will execute the SELECT statement.
Generating and analyzing the query execution plan is a crucial step in identifying performance bottlenecks and
optimizing database queries.

## Indices

In the context of SQL databases, an index is a special lookup table that the database search engine can use to speed up
data retrieval. It functions similarly to an index in a book, allowing the database to quickly locate specific rows
without having to scan the entire table.

**Advantages of using indices in SQL**

**Faster Query Performance**: Indices significantly reduce the time required to execute SELECT statements, especially
those with WHERE, JOIN, or ORDER BY clauses on indexed columns. This is because the database can directly access the
relevant data without performing a full table scan.

**Improved Sorting and Grouping**: Queries involving ORDER BY and GROUP BY clauses can benefit from indexes as the
indexed data is often pre-sorted, reducing the need for the database engine to perform sorting operations during query
execution.

**Data Integrity Enforcement**: Unique indexes, like those on primary keys, enforce uniqueness constraints on the
indexed columns, preventing duplicate entries and maintaining data integrity.

**Efficient Data Access**: Indexes can reduce disk I/O by allowing the database to quickly locate and retrieve only the
necessary data, rather than scanning large portions of the table.

Creating an index in SQL:

```sql

CREATE INDEX index_name
ON table_name (column1, column2, ...);
```

Example:

```sql

CREATE INDEX idx_lastname
ON Customers (LastName);
```

This creates an index named idx_lastname on the LastName column of the Customers table, which will speed up queries
filtering or ordering by the LastName column.

*Note*: While indices offer significant performance benefits for read operations, they do come with trade-offs. They
consume additional storage space and can add overhead to write operations (INSERT, UPDATE, DELETE) as the index
structure also needs to be updated. Therefore, careful consideration is required when deciding which columns to index.

### How does index work?

SQL indexes are special lookup tables that the database search engine can use to speed up data retrieval. They function
similarly to the index in a book. Instead of scanning every page (or row in a table) to find specific information, an
index provides a direct path to the data.
Here's how indexes generally work in SQL:
Creation: When an index is created on one or more columns of a table, the database system builds a separate data
structure, typically a B-tree (or a variation like a B+ tree). This structure contains the values from the indexed
columns, sorted, along with pointers (row locators) to the actual data rows in the main table.
Storage: This index structure is stored separately from the main table data. For example, a clustered index physically
sorts and stores the data rows themselves based on the index key, while a nonclustered index stores the index key values
and pointers to the data rows, which can be in a different order.
Querying: When a query involves searching, filtering, or sorting based on the indexed columns, the database optimizer
can choose to use the index instead of performing a full table scan.
Lookup: The database system traverses the sorted index structure (e.g., the B-tree) to quickly find the relevant index
key values. Since the index is sorted, this search is highly efficient, often logarithmic in complexity (O(log n)).
Data Retrieval: Once the index locates the desired key values, it uses the associated pointers to directly access the
corresponding data rows in the main table. This avoids the need to read and process every row in the table,
significantly reducing disk I/O and improving query performance, especially for large tables.
In essence, indexes provide a fast and efficient way to locate specific data within a table by creating an organized and
searchable structure of key values and their corresponding data locations.

### What is the best data type to use as an index.

The best data type to use as an index in SQL is generally a narrow, fixed-length, and frequently used data type, with
integers being the preferred choice for primary keys and clustered indexes.
Here's a breakdown of why and considerations for other data types:
Integers (INT, BIGINT):
Why they are best: Integers are compact, fixed-length, and highly efficient for comparisons and sorting, which are
fundamental operations for indexes. They result in smaller index sizes and faster lookups.
Use cases: Ideal for primary keys, foreign keys, and any column with unique or highly selective numeric values.
Fixed-length character strings (CHAR, NCHAR):
Considerations: Fixed-length strings can be efficient if the length is relatively small and consistent. They offer
predictable storage and retrieval.
Use cases: Suitable for short, fixed-length codes or identifiers where the length is known and doesn't vary
significantly.
Dates and times (DATE, DATETIME, TIMESTAMP):
Considerations: These data types are also fixed-length and can be effectively indexed, especially when queries
frequently involve date ranges or ordering by time.
Use cases: Columns used for filtering by date, ordering by timestamp, or analyzing time-series data.
Variable-length character strings (VARCHAR, NVARCHAR):
Considerations: While usable, variable-length strings can lead to larger index sizes and potentially slower performance
compared to fixed-length types, especially if the string lengths vary widely.
Use cases: When fixed-length strings are not feasible, but keep the length as short as possible.
GUIDs (UNIQUEIDENTIFIER):
Considerations: GUIDs are large and inherently random, which can lead to poor performance for clustered indexes due to
page splits and fragmentation.
Use cases: More suitable for non-clustered indexes where uniqueness is paramount and sequential ordering is not a
primary concern.
General Guidelines for Indexing Data Types:
Choose the smallest data type that meets your requirements. Smaller data types result in smaller indexes, leading to
better performance.
Prioritize fixed-length over variable-length data types when possible.
Avoid indexing large, variable-length data types like TEXT, NTEXT, BLOB, or IMAGE unless absolutely necessary, and
consider full-text indexing for such cases.
Consider the selectivity of the column. Columns with high selectivity (many distinct values) benefit more from indexing.
Align index order with common query patterns. If you frequently sort or filter by a specific order (e.g., ORDER BY
Timestamp DESC), define the index with that order.

### Is it good to have too many indices?

Having too many indexes on a SQL database table is generally not beneficial and can lead to several performance
drawbacks. While indexes are crucial for speeding up data retrieval, excessive indexing can negatively impact database
performance, particularly for write-heavy operations.

**Disadvantages of Too Many Indexes**

**Slower Write Operations**: Each index needs to be updated whenever data in the table is inserted, updated, or deleted.
More indexes mean more work for the database system, leading to slower INSERT, UPDATE, and DELETE operations.

**Increased Storage Space**: Indexes consume disk space. A large number of indexes, especially on large tables, can
significantly increase the overall storage footprint of the database.

**Higher Resource Consumption**: Maintaining and updating numerous indexes requires more CPU and I/O resources,
potentially impacting the performance of other database operations.

**Complex Query Optimization**: With many indexes, the query optimizer has more options to consider when creating an
execution plan. This increased complexity can sometimes lead to the optimizer choosing a less efficient plan, or simply
taking longer to determine the optimal plan.

**Reduced Cache Efficiency**: In environments with high write activity, frequent updates to many indexes can cause index
pages to be constantly swapped in and out of memory, reducing the effectiveness of the database cache.

**Redundancy and Maintenance Overhead**: Over-indexing can result in redundant indexes that provide little or no
benefit, yet still require maintenance and consume resources.

**Best Practices for Indexing**

**Index Foreign Keys**: Indexing foreign key columns is generally recommended as it improves the performance of JOIN
operations.

**Index Frequently Queried Columns**: Create indexes on columns frequently used in WHERE, ORDER BY, and GROUP BY
clauses, especially those with high cardinality (many unique values).

**Consider Composite Indexes**: For queries involving multiple columns in filtering or sorting, a composite index (an
index on multiple columns) can be more efficient than multiple single-column indexes.

**Monitor and Analyze**: Regularly analyze query performance and index usage to identify unused or redundant indexes
that can be removed.

**Balance Read and Write Workloads**: Strike a balance between optimizing for read performance (which benefits from
indexes) and minimizing the overhead on write operations.

In essence, while indexes are valuable tools for performance optimization, a thoughtful and strategic approach to
indexing is crucial to avoid the pitfalls of over-indexing. The goal is to create only the necessary indexes that
significantly improve query performance without unduly impacting write operations or consuming excessive resources.

# Primary key

A primary key (PK) in SQL is a column or a set of columns in a database table that uniquely identifies each row or
record within that table. It serves as the main identifier for rows and enforces data integrity by preventing duplicate
records and null values in the specified column(s).

**Key characteristics of a primary key in SQL**

**Uniqueness**: Every value in the primary key column(s) must be unique. No two rows can have the same primary key
value.

**Not Null**: A primary key column cannot contain NULL values. Each row must have a defined value for its primary key.

**Single per table**: A table can have only one primary key constraint.

**Indexing**: The database engine automatically creates a unique index on the primary key columns, which facilitates
fast data retrieval when the primary key is used in queries.

# Exercice

a. Some SQL query to fetch the names of department and the count from the table where the employeesâ€™ count is more than
10.

```sql
SELECT
    d.department_name,
    COUNT(e.employee_id) AS employee_count
FROM
    Departments AS d
JOIN
    Employees AS e ON d.department_id = e.department_id
GROUP BY
    d.department_name
HAVING
    COUNT(e.employee_id) > 10;
```    

# Primary key, unique key and foreign keys.

Primary keys uniquely identify a row in a table and cannot contain NULL values. Unique keys ensure a column's values are
unique, but can contain a single NULL value, unlike primary keys. Foreign keys establish a link between two tables, with
the column in one table referencing the primary key of another, and can contain duplicates and NULLs.

## 9. Difference between Stored Proc and Functions

## 10. What is Normalization? Why use normalization?

## 11. What are SQL joins and their types?

# Delete, Truncate and Drop

The DELETE, TRUNCATE, and DROP commands in SQL are used to remove data or database objects, but they differ
significantly in their scope, behavior, and reversibility.

1. DELETE

**Purpose**: Removes specific rows from a table based on a specified WHERE clause. If no WHERE clause is provided, all
rows are deleted.

**Type**: Data Manipulation Language (DML) command.

**Logging**: Logs each deleted row, allowing for transactional rollback.

**Performance**: Generally slower than TRUNCATE for deleting all rows, as it processes each row individually.

**Triggers**: Fires DELETE triggers defined on the table.

Syntax:

```sql
    DELETE FROM table_name WHERE condition;
```

or

```sql
    DELETE FROM table_name;
```

2. TRUNCATE

**Purpose**: Removes all rows from a table, effectively emptying it, but retains the table's structure (schema),
indexes, and constraints.

**Type**: Data Definition Language (DDL) command.

**Logging**: Minimal logging, as it deallocates the data pages rather than logging individual row deletions. This
typically makes it faster than DELETE for removing all rows.

**Performance**: Faster than DELETE for removing all rows.
Triggers: Does not fire DELETE triggers.

**Rollback**: Not typically reversible in most database systems, although some (like PostgreSQL and SQL Server) support
it within a transaction.

Syntax:

```sql

    TRUNCATE TABLE table_name;
```

3. DROP

**Purpose**: Permanently removes an entire database object, such as a table, including its structure, data, indexes,
constraints, and any associated privileges or triggers.

**Type**: Data Definition Language (DDL) command.

**Logging**: Logs the dropping of the object, but the data itself is not recoverable without a backup.

**Performance**: Generally the fastest for removing an entire table, as it deallocates the entire object.

**Triggers**: Removes any associated triggers along with the table.

**Rollback**: Not reversible; once a table is dropped, it cannot be recovered without restoring from a backup.

Syntax:

```sql

    DROP TABLE table_name;
```